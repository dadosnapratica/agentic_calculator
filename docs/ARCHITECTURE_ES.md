
# ğŸ—ï¸ Arquitectura - Calculadora Agentic PoC

**DocumentaciÃ³n tÃ©cnica detallada de la arquitectura multiâ€‘agente con LLM local**

---

> ğŸ‡§ğŸ‡· [VersÃ£o Original em PortuguÃªs (Brasil)](ARCHITECTURE_BR.md)  
> **Aviso:** Esta Ã© a versÃ£o original da documentaÃ§Ã£o tÃ©cnica. Para mÃ¡xima precisÃ£o conceitual e tÃ©cnica, utilize preferencialmente esta versÃ£o.

> ğŸ‡ºğŸ‡¸ [English Version](ARCHITECTURE.md)  
> **Disclaimer:** This documentation is also available in English. For official technical reference, consult the Portuguese or English versions.

> ğŸ‡ªğŸ‡¸ [DocumentaciÃ³n en EspaÃ±ol](ARCHITECTURE_ES.md)  
> **Aviso:** La documentaciÃ³n tambiÃ©n estÃ¡ disponible en espaÃ±ol. Para mayor precisiÃ³n tÃ©cnica, consulte la versiÃ³n original en portuguÃ©s o la versiÃ³n en inglÃ©s.

---


## ğŸ“‹ Ãndice

- VisiÃ³n General
- Principios de DiseÃ±o
- Componentes
- Flujo de Datos
- Decisiones ArquitectÃ³nicas
- Seguridad
- Escalabilidad
- Stack TecnolÃ³gico

---

## ğŸ¯ VisiÃ³n General

### Arquitectura en Capas

Capa de PresentaciÃ³n â†’ Capa de OrquestaciÃ³n â†’ Capa de Especialistas â†’ Capa de Modelo â†’ Capa de Infraestructura  

Capa Transversal: Seguridad, Logging y ConfiguraciÃ³n.

---

## ğŸ§© Principios de DiseÃ±o

### 1. SeparaciÃ³n de Responsabilidades
Cada componente posee una **responsabilidad Ãºnica**:

- Orchestrator: CoordinaciÃ³n y flujo
- LLMClient: ComunicaciÃ³n con el modelo
- Specialists: EjecuciÃ³n de operaciones
- Sandbox: ValidaciÃ³n de seguridad

### 2. Principio Abierto/Cerrado
El sistema estÃ¡ abierto para extensiones y cerrado para modificaciones.

### 3. InyecciÃ³n de Dependencias
Los componentes reciben sus dependencias mediante el constructor.

### 4. Failâ€‘Safe
El sistema falla de forma controlada y devuelve errores estructurados.

---

## ğŸ”§ Componentes

### CalculatorOrchestrator
Responsable de coordinar todo el pipeline:

1. PlanificaciÃ³n (LLM)
2. ValidaciÃ³n (Seguridad)
3. EjecuciÃ³n (Specialists)
4. ConsolidaciÃ³n de resultados

### LLMClient
Gestiona la comunicaciÃ³n con el modelo de lenguaje:

- GeneraciÃ³n de respuestas
- ConversiÃ³n de lenguaje natural a operaciones estructuradas

### Specialists
Ejecutan operaciones especÃ­ficas siguiendo el **Strategy Pattern**:

- Operaciones bÃ¡sicas
- Operaciones avanzadas
- Operaciones estadÃ­sticas

### Sandbox
Garantiza la ejecuciÃ³n segura mediante:

- Lista blanca de operaciones
- Timeout de ejecuciÃ³n
- ValidaciÃ³n de argumentos
- Registro de auditorÃ­a
- Aislamiento de errores

---

## ğŸ”„ Flujo de Datos

Entrada del usuario â†’ Orchestrator â†’ PlanificaciÃ³n LLM â†’ ValidaciÃ³n â†’ EjecuciÃ³n â†’ ConsolidaciÃ³n â†’ PresentaciÃ³n.

El resultado final incluye:
- Resultado final
- Resultados intermedios
- Plan ejecutado
- Metadatos de ejecuciÃ³n

---

## ğŸ¨ Decisiones ArquitectÃ³nicas

### Â¿Por quÃ© un LLM Local?

Seleccionado por:

- Privacidad
- Costo operativo cero
- ExperimentaciÃ³n local
- Base para sistemas sensibles como trading

### Â¿Por quÃ© Streamlit?

Elegido debido a:

- Desarrollo rÃ¡pido
- IntegraciÃ³n nativa con Python
- Ideal para Proof of Concept

### Â¿Por quÃ© Arquitectura Multiâ€‘Agente?

Beneficios:

- DiseÃ±o modular
- Facilidad de pruebas
- Escalabilidad
- Modelo natural de delegaciÃ³n entre agentes

---

## ğŸ”’ Seguridad

Mecanismos principales:

- Lista blanca de operaciones
- ValidaciÃ³n estricta de argumentos
- Timeout por operaciÃ³n
- Logging completo
- Aislamiento de fallos

Amenazas mitigadas:

- Prompt Injection
- Code Injection
- DenegaciÃ³n de servicio
- ExfiltraciÃ³n de datos
- Escalada de privilegios

---

## ğŸ“ˆ Escalabilidad

### Escalado Vertical (Actual)
Un Ãºnico proceso de orquestaciÃ³n maneja las solicitudes.

### Escalado Horizontal (Futuro)

- Balanceador de carga
- MÃºltiples orquestadores
- Pool de modelos LLM
- Procesamiento basado en colas
- EjecuciÃ³n asÃ­ncrona

Soporte para trazabilidad distribuida mediante OpenTelemetry.

---

## ğŸ› ï¸ Stack TecnolÃ³gico

Backend:
- Python 3.9+
- ConfiguraciÃ³n YAML
- asyncio (futuro)

LLM:
- Ollama
- Mistral 7B Instruct
- Ventana de contexto de 8K tokens

Frontend:
- Streamlit
- CLI (futuro)

Infraestructura:
- Ubuntu / WSL2
- Docker (futuro)
- Docker Compose (futuro)

---

## ğŸ”„ Patrones de DiseÃ±o Utilizados

- Strategy Pattern
- Factory Pattern
- Template Method
- Observer Pattern

---

## ğŸ“Š MÃ©tricas y MonitorizaciÃ³n

MÃ©tricas clave:

- Latencia total
- Latencia del LLM
- Tasa de Ã©xito
- Tasa de errores
- Uso de recursos
- Operaciones por minuto

---

## ğŸš€ EvoluciÃ³n ArquitectÃ³nica

Fase 1 â€” PoC  
Usuario â†’ Streamlit â†’ Orchestrator â†’ LLM â†’ Specialists

Fase 2 â€” ProducciÃ³n  
Balanceador + mÃºltiples orquestadores + workers

Fase 3 â€” Arquitectura Distribuida  
API Gateway + Kubernetes + Service Mesh + Message Broker

---

## ğŸ“š Referencias

- ReAct Paper
- Chainâ€‘ofâ€‘Thought Prompting
- AutoGPT

Inspirado en:

- LangChain
- AutoGen
- CrewAI

---

## ğŸ¤ Contribuciones

Los cambios deben seguir el proceso ADR (Architecture Decision Record).

Ejemplo:
ADRâ€‘001 â€” Implementar cachÃ© de planes LLM usando Redis con TTL.

---

**Creado con ğŸ—ï¸ por Flavio Lopes | Arquitectura v1.0 | 2026**
